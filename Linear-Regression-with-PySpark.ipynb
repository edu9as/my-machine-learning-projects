{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predicting Crew Members with Linear Regression using PySpark</h1>\n",
    "\n",
    "In this notebook, I am creating a regression model that will help predict how many crew members will be needed for Hyundai Heavy Industries ships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1: Create a new Spark session</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PredictingCrewMembers\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2: Load the data</h2>\n",
    "\n",
    "First I'm loading a csv with cruise ships information called <code>cruise_ship_info.csv</code>, which you can find online <a href=\"https://raw.githubusercontent.com/kushangbhatt/CrewMemberPrediction/master/cruise_ship_info.csv\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"cruise_ship_info.csv\"\n",
    "df = spark.read.csv(file, header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This dataset has {} columns.\\n\\nThe names of these columns are:\\n  {}\".format(len(df.columns), df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data\n",
    "\n",
    "Now, it is important to first examine the data we have. The first five rows in the dataset look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can see the schema of the database in a tree format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **crew**, which is continuous. So are most of the features in this dataset. Only **Ship_name** and **Cruise_line** are categorical variables.\n",
    "\n",
    "Below, a summary of the database is shown in <em>Pandas</em> format. Here we can see mean, standard deviation, minimum and maximum values for each numerical column. Also, notice that there are 158 rows in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to explore how many unique values are there in both categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"Ship_name\", \"Cruise_line\"]:    \n",
    "    print(\"There are %s different values in %s column.\" % (df.select(column).distinct().count(), column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ship_name** has roughly as many distinct values as rows are there in the dataset. Then, I think this feature is not very informative for predicting crew members, so I decide not to include it in the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I am converting the **Cruise_line** column to numerical labels for each string. I want to include this variable in the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Cruise_line\", outputCol=\"line_id\")\n",
    "indexed = indexer.fit(df).transform(df)\n",
    "indexed.select(\"line_id\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the strings in **Cruise_line** have been transformed to numerical values between 0 and 19. Now, we can include this numerical variable in the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([int(row.line_id) for row in indexed.select(\"line_id\").distinct().orderBy(\"line_id\").collect()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indexed.schema.names)):\n",
    "    print(\"Column number\", i, \"is\", indexed.schema.names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to include in the linear regression model as predictor variables all columns between 2 and 9 except column number 8, which is the target variable. Knowing this, the vector assembler with all features for the linear regression model is created in the next block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = [indexed.schema.names[i] for i in [9] + list(range(2,8))],\n",
    "                            outputCol = \"features\")\n",
    "output = assembler.transform(indexed)\n",
    "output.select(\"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features vector has been correctly generated. Next, I am fitting a linear regression model that considers these seven features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Splitting of final_data in train (70%) and test (30%) sets. Random seed is\n",
    "#   set to today's date, 2020-12-21\n",
    "\n",
    "train_data, test_data = output.randomSplit([0.7, 0.3], seed = 20201221)\n",
    "\n",
    "\n",
    "# Fitting linear regression model with train_data\n",
    "\n",
    "lr = LinearRegression(labelCol=\"crew\")\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does this model predicts crew members? I am evaluating its performance in terms of RMSE and R²:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating linear regression model with test_data\n",
    "test_results = lr_model.evaluate(test_data)\n",
    "\n",
    "\n",
    "# Outputting R-squared of this model\n",
    "print(\"RMSE of model =\", test_results.rootMeanSquaredError)\n",
    "print(\"R-squared of model =\", test_results.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R² is very close to 1 and RMSE is quite low, so this model seems adequate to make predictions about the number of crew members given some features.\n",
    "\n",
    "However, what would had happened if I hadn't included **Cruise_line** as a numerical variable (**line_id**) in the model? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler2 = VectorAssembler(inputCols = [df.columns[i] for i in range(2,8)], outputCol = \"features\")\n",
    "\n",
    "output2 = assembler2.transform(df)\n",
    "\n",
    "# Splitting of final_data in train (70%) and test (30%) sets. Random seed is\n",
    "#   set to today's date, 2020-11-04\n",
    "\n",
    "train_data2, test_data2 = output2.randomSplit([0.7, 0.3], seed = 20201221)\n",
    "\n",
    "\n",
    "# Fitting linear regression model with train_data\n",
    "\n",
    "lr_model2 = lr.fit(train_data2)\n",
    "\n",
    "\n",
    "# Evaluating linear regression model with test_data\n",
    "test_results2 = lr_model2.evaluate(test_data2)\n",
    "\n",
    "\n",
    "# Outputting R-squared of this model\n",
    "print(\"RMSE of model =\", test_results2.rootMeanSquaredError)\n",
    "print(\"R-squared of model =\", test_results2.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both models perform very well, in terms of RMSE and R². Then, we might think that **Cruise_line** is not a very informative predictor variable.\n",
    "\n",
    "This is just a very simple example, but linear regression can be applied to a lot of more complex and interesting tasks using Spark. I hope you have enjoyed this notebook, see you soon!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
