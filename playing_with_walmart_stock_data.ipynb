{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with Walmart Stock Data\n",
    "\n",
    "In this notebook, I am trying some basic things with Pyspark. \n",
    "\n",
    "First, I am starting a simple Spark session:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"dfbasics\").getOrCreate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I am using a dataset stored in `walmart_stock.csv`.\n",
    "I don't know whether I can share it or not, so I prefer not sharing it by now. \n",
    "\n",
    "Then, the next step is to load this Walmart Stock CSV file and let Spark infer the data types.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"walmart_stock.csv\"\n",
    "df = spark.read.csv(file, header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a glance at this dataset using Pyspark. How many columns does this dataset have and which are their names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 7 columns. Their names are:\n",
      "  ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n"
     ]
    }
   ],
   "source": [
    "print(\"This dataset has {} columns. Their names are:\\n  {}\".format(len(df.columns), df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what kind of values contains each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all columns except Date (string values) and Volume (integer values) contain doubles.\n",
    "\n",
    "Now I am wondering how this dataset looks like, so I am printing out its first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>59.970001</td>\n",
       "      <td>61.060001</td>\n",
       "      <td>59.869999</td>\n",
       "      <td>60.330002</td>\n",
       "      <td>12668800</td>\n",
       "      <td>52.619235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>60.209999</td>\n",
       "      <td>60.349998</td>\n",
       "      <td>59.470001</td>\n",
       "      <td>59.709999</td>\n",
       "      <td>9593300</td>\n",
       "      <td>52.078475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>59.349998</td>\n",
       "      <td>59.619999</td>\n",
       "      <td>58.369999</td>\n",
       "      <td>59.419998</td>\n",
       "      <td>12768200</td>\n",
       "      <td>51.825539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>59.419998</td>\n",
       "      <td>59.450001</td>\n",
       "      <td>58.869999</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>8069400</td>\n",
       "      <td>51.459220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>59.029999</td>\n",
       "      <td>59.549999</td>\n",
       "      <td>58.919998</td>\n",
       "      <td>59.180000</td>\n",
       "      <td>6679300</td>\n",
       "      <td>51.616215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close    Volume  Adj Close\n",
       "0  2012-01-03  59.970001  61.060001  59.869999  60.330002  12668800  52.619235\n",
       "1  2012-01-04  60.209999  60.349998  59.470001  59.709999   9593300  52.078475\n",
       "2  2012-01-05  59.349998  59.619999  58.369999  59.419998  12768200  51.825539\n",
       "3  2012-01-06  59.419998  59.450001  58.869999  59.000000   8069400  51.459220\n",
       "4  2012-01-09  59.029999  59.549999  58.919998  59.180000   6679300  51.616215"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the dataset to show is small, I prefer to convert the Spark dataframe to a Pandas dataframe. However, this is not the command which can be used for printing a dataframe. In the two following pieces of code I am doing the same with .show(5), and with .sql().show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('dataset')\n",
    "spark.sql('SELECT * FROM dataset LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the SQL command, I am using registerTempTable('dataset') method so that besides being able to use the methods provided by Spark, I can also employ SQL queries.\n",
    "\n",
    "Next, I use **describe()** to get some more information about the dataframe: count, mean, standard deviation, minimum and maximum for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>1258</td>\n",
       "      <td>1258</td>\n",
       "      <td>1258</td>\n",
       "      <td>1258</td>\n",
       "      <td>1258</td>\n",
       "      <td>1258</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>72.35785375357709</td>\n",
       "      <td>72.83938807631165</td>\n",
       "      <td>71.9186009594594</td>\n",
       "      <td>72.38844998012726</td>\n",
       "      <td>8222093.481717011</td>\n",
       "      <td>67.23883848728146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>6.76809024470826</td>\n",
       "      <td>6.768186808159218</td>\n",
       "      <td>6.744075756255496</td>\n",
       "      <td>6.756859163732991</td>\n",
       "      <td>4519780.8431556</td>\n",
       "      <td>6.722609449996857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>56.389998999999996</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>56.419998</td>\n",
       "      <td>2094900</td>\n",
       "      <td>50.363689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>90.800003</td>\n",
       "      <td>90.970001</td>\n",
       "      <td>89.25</td>\n",
       "      <td>90.470001</td>\n",
       "      <td>80898100</td>\n",
       "      <td>84.91421600000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary        Date                Open               High  \\\n",
       "0   count        1258                1258               1258   \n",
       "1    mean        None   72.35785375357709  72.83938807631165   \n",
       "2  stddev        None    6.76809024470826  6.768186808159218   \n",
       "3     min  2012-01-03  56.389998999999996          57.060001   \n",
       "4     max  2016-12-30           90.800003          90.970001   \n",
       "\n",
       "                 Low              Close             Volume          Adj Close  \n",
       "0               1258               1258               1258               1258  \n",
       "1   71.9186009594594  72.38844998012726  8222093.481717011  67.23883848728146  \n",
       "2  6.744075756255496  6.756859163732991    4519780.8431556  6.722609449996857  \n",
       "3          56.299999          56.419998            2094900          50.363689  \n",
       "4              89.25          90.470001           80898100  84.91421600000001  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might think that it is ugly how all values were represented in the previous dataframes (more than 6 decimal places? Awful!). Now, I am formatting the dataset so that it only shows up to two decimal places. This one was a little hard for a beginner and was my teacher José Manuel Moya who solved it, so all credits to him!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>1258</td>\n",
       "      <td>1,258.00</td>\n",
       "      <td>1,258.00</td>\n",
       "      <td>1,258.00</td>\n",
       "      <td>1,258.00</td>\n",
       "      <td>1,258.00</td>\n",
       "      <td>1,258.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>72.36</td>\n",
       "      <td>72.84</td>\n",
       "      <td>71.92</td>\n",
       "      <td>72.39</td>\n",
       "      <td>8,222,093.50</td>\n",
       "      <td>67.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>6.77</td>\n",
       "      <td>6.77</td>\n",
       "      <td>6.74</td>\n",
       "      <td>6.76</td>\n",
       "      <td>4,519,781.00</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>56.39</td>\n",
       "      <td>57.06</td>\n",
       "      <td>56.30</td>\n",
       "      <td>56.42</td>\n",
       "      <td>2,094,900.00</td>\n",
       "      <td>50.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>90.80</td>\n",
       "      <td>90.97</td>\n",
       "      <td>89.25</td>\n",
       "      <td>90.47</td>\n",
       "      <td>80,898,096.00</td>\n",
       "      <td>84.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary        Date      Open      High       Low     Close         Volume  \\\n",
       "0   count        1258  1,258.00  1,258.00  1,258.00  1,258.00       1,258.00   \n",
       "1    mean        None     72.36     72.84     71.92     72.39   8,222,093.50   \n",
       "2  stddev        None      6.77      6.77      6.74      6.76   4,519,781.00   \n",
       "3     min  2012-01-03     56.39     57.06     56.30     56.42   2,094,900.00   \n",
       "4     max  2016-12-30     90.80     90.97     89.25     90.47  80,898,096.00   \n",
       "\n",
       "  Adj Close  \n",
       "0  1,258.00  \n",
       "1     67.24  \n",
       "2      6.72  \n",
       "3     50.36  \n",
       "4     84.91  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "desc = df.describe()\n",
    "desc.select('summary', 'Date', \n",
    "            format_number(desc['Open'].cast('float'), 2).alias('Open'),\n",
    "            format_number(desc['High'].cast('float'), 2).alias('High'),\n",
    "            format_number(desc['Low'].cast('float'), 2).alias('Low'),\n",
    "            format_number(desc['Close'].cast('float'), 2).alias('Close'),\n",
    "            format_number(desc['Volume'].cast('float'), 2).alias('Volume'),\n",
    "            format_number(desc['Adj Close'].cast('float'), 2).alias('Adj Close')\n",
    "           ).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the appearence of the description dataframe has improved a lot.\n",
    "\n",
    "In the following code cell I'm creting a new DataFrame with a column called **HV Ratio**, which is the ratio of the High Price vs Volume of Stock traded for a day. Thanks to the method **.withColumn()**, we can add new columns to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.withColumn(\"HV Ratio\", df[\"High\"]/df[\"Volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>HV Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>59.970001</td>\n",
       "      <td>61.060001</td>\n",
       "      <td>59.869999</td>\n",
       "      <td>60.330002</td>\n",
       "      <td>12668800</td>\n",
       "      <td>52.619235</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>60.209999</td>\n",
       "      <td>60.349998</td>\n",
       "      <td>59.470001</td>\n",
       "      <td>59.709999</td>\n",
       "      <td>9593300</td>\n",
       "      <td>52.078475</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>59.349998</td>\n",
       "      <td>59.619999</td>\n",
       "      <td>58.369999</td>\n",
       "      <td>59.419998</td>\n",
       "      <td>12768200</td>\n",
       "      <td>51.825539</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>59.419998</td>\n",
       "      <td>59.450001</td>\n",
       "      <td>58.869999</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>8069400</td>\n",
       "      <td>51.459220</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>59.029999</td>\n",
       "      <td>59.549999</td>\n",
       "      <td>58.919998</td>\n",
       "      <td>59.180000</td>\n",
       "      <td>6679300</td>\n",
       "      <td>51.616215</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close    Volume  \\\n",
       "0  2012-01-03  59.970001  61.060001  59.869999  60.330002  12668800   \n",
       "1  2012-01-04  60.209999  60.349998  59.470001  59.709999   9593300   \n",
       "2  2012-01-05  59.349998  59.619999  58.369999  59.419998  12768200   \n",
       "3  2012-01-06  59.419998  59.450001  58.869999  59.000000   8069400   \n",
       "4  2012-01-09  59.029999  59.549999  58.919998  59.180000   6679300   \n",
       "\n",
       "   Adj Close  HV Ratio  \n",
       "0  52.619235  0.000005  \n",
       "1  52.078475  0.000006  \n",
       "2  51.825539  0.000005  \n",
       "3  51.459220  0.000007  \n",
       "4  51.616215  0.000009  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to know what day had the peak High. First, I am storing a float containing the value of the maximum in **High**, through the use of a resilient distributed dataset (.rdd). With this value being stored, it is easy to filter the dataframe and select the **Date** with the maximum **High** value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-01-13'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_high = df.select(\"High\").rdd.max()[0]\n",
    "\n",
    "df.filter(df[\"High\"] == max_high).select(\"Date\").head()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easier way to solve this is to issue a SQL query, selecting only the first value in **Date** column after ordering the dataset by **High** in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-01-13'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('SELECT Date FROM dataset ORDER BY High DESC LIMIT 1').head()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible question: what is the mean of the some column? For example, **Close**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.38844998012726\n"
     ]
    }
   ],
   "source": [
    "one_possible_answer = df.agg({\"Close\": \"mean\"}).head()[0]\n",
    "another_possible_answer = spark.sql('SELECT MEAN(Close) FROM dataset').head()[0]\n",
    "\n",
    "if one_possible_answer == another_possible_answer:\n",
    "    print(one_possible_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see we can solve this question through the use of **.agg** method and with a SQL query.\n",
    "\n",
    "And what if I wanted to know what is the maximum (or minimum) value of a given column? For example, **Volume**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using .agg() Spark method:\n",
      "\n",
      "+-----------+-----------+\n",
      "|min(Volume)|max(Volume)|\n",
      "+-----------+-----------+\n",
      "|    2094900|   80898100|\n",
      "+-----------+-----------+\n",
      "\n",
      "    Using a SQL query:\n",
      "\n",
      "+-----------+-----------+\n",
      "|min(Volume)|max(Volume)|\n",
      "+-----------+-----------+\n",
      "|    2094900|   80898100|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using .agg() Spark method:\\n\")\n",
    "df.agg(F.min(F.col(\"Volume\")), F.max(F.col(\"Volume\"))).show()\n",
    "\n",
    "print(\"    Using a SQL query:\\n\")\n",
    "spark.sql('SELECT MIN(Volume), MAX(Volume) FROM dataset').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also here, we obtain the same result both with .agg() method and with a SQL query.\n",
    "\n",
    "Next question: how many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 81 days where Close was lower than 60 dollars.\n"
     ]
    }
   ],
   "source": [
    "one_possible_answer = df.where(df[\"Close\"] < 60).count()\n",
    "another_possible_answer = spark.sql('SELECT COUNT(CASE WHEN Close < 60 THEN 1 END) FROM dataset').head()[0]\n",
    "\n",
    "if one_possible_answer == another_possible_answer:\n",
    "    print(\"There were {} days where Close was lower than 60 dollars.\".format(one_possible_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more questions:\n",
    "\n",
    "What percentage of time was **High** column greater than 80 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9%\n"
     ]
    }
   ],
   "source": [
    "print(\"%.0f%%\" % (df.filter(df[\"High\"]>80).count()/df.count()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the Pearson correlation between High and Volume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pearson correlation between High and Volume columns is -0.34\n"
     ]
    }
   ],
   "source": [
    "print(\"The Pearson correlation between High and Volume columns is %.2f\" % df.stat.corr(\"High\", \"Volume\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two variables have a low negative correlation.\n",
    "\n",
    "What is the max High per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|max(High)|\n",
      "+----+---------+\n",
      "|2012|77.599998|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2015|90.970001|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT year(Date) AS Year, max(High) FROM dataset GROUP BY year(Date) ORDER BY year(Date)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, what is the average Close for each calendar month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Month|      mean(Close)|\n",
      "+-----+-----------------+\n",
      "|    1|71.44801958415842|\n",
      "|    2|  71.306804443299|\n",
      "|    3|71.77794377570092|\n",
      "|    4|72.97361900952382|\n",
      "|    5|72.30971688679247|\n",
      "|    6| 72.4953774245283|\n",
      "|    7|74.43971943925233|\n",
      "|    8|73.02981855454546|\n",
      "|    9|72.18411785294116|\n",
      "|   10|71.57854545454543|\n",
      "|   11| 72.1110893069307|\n",
      "|   12|72.84792478301885|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT month(Date) AS Month, mean(Close) FROM dataset GROUP BY month(Date) ORDER BY month(Date)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have made an introduction of some basic functionalities of Spark to deal with datasets. These exercises were proposed by José Manuel Moya, my instructor in Big Data Engineering subject.\n",
    "\n",
    "I hope you enjoy this work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
